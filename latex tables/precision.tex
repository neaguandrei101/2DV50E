\documentclass{article}
\begin{document}
\begin{table}
\centering
\caption{steps}
\begin{tabular}{lll}
Source                                                         & Validation                                                                                                                                                                                                                                                                                                                                  & Details                                                                                                                                                                                                                                                                                                                                                                         \\
Palma et al.\textbackslash{}cite\{palma2014detection\}         & \begin{tabular}[c]{@{}l@{}}Average precision = 89.42\% \\Average recall = 94\%\\Average F - measure = 91.65\%\end{tabular}                                                                                                                                                                                                                  & All APIs tested                                                                                                                                                                                                                                                                                                                                                                 \\
Palma et al.\textbackslash{}cite\{palma2015restful\}           & \begin{tabular}[c]{@{}l@{}}\textbf{Validation 1}\\\textbf{}Average Precision= 81.4\%\\Average Recall = 78\% \\Average F-measure = 79.66\% \\\textbf{Validation 2}\\\textbf{}Average Precision = 79.7\% \end{tabular}                                                                                                                        & \begin{tabular}[c]{@{}l@{}}Validation 1 - All URIs, only Dropbox verified\\Validation 2 - Partial set of tested URIs on \\Facebook, Dropbox, Twitter,and YouTube\\No recall or F-measure calculated due to partial validation\end{tabular}                                                                                                                                      \\
Brabra et al.\textbackslash{}cite\{brabra2016detecting\}       & \begin{tabular}[c]{@{}l@{}}Average Precision = 98 \%\\Average Recall = 100 \% \\Average F1-measure = 99 \%\end{tabular}                                                                                                                                                                                                                     & \begin{tabular}[c]{@{}l@{}}Validation on OpenStack,Microsoft and Rackspace\\for REST antipatterns\end{tabular}                                                                                                                                                                                                                                                                  \\
Palma et al.\textbackslash{}cite\{palma2017semantic\}          & \begin{tabular}[c]{@{}l@{}}\textbf{Validation 1}\\DOLAR\\Average precision = 81.3\% \\Average recall = 78.0\% \\VS SARA\\Average Precision= 80.9\%\\Average Recall = 81.0\%\\\textbf{Validation 2}\\DOLAR\\Average precision = 79.7\%\\VS SARA\\Average precision = 87.3\% \\\textbf{Validation 3}\\Average precision = 73.2\%\end{tabular} & \begin{tabular}[c]{@{}l@{}}Validation 1 and 2 - Same antipatterns and dataset as before\\Validation 1 - All URIs, only Dropbox verified\\Validation 2 - Partial set of tested URIs on \\Facebook, Dropbox, Twitter,and YouTube\\No recall or F-measure calculated due to partial validation\\Validation 3 - All antipatterns\\Validation 3 - All URIs in all APIs\end{tabular}  \\
Belkhir et al.\textbackslash{}cite\{belkhir2019observational\} & \begin{tabular}[c]{@{}l@{}}Average Precision = 93.70\% \\Average Recall = 87.66\%\textbf{}\end{tabular}                                                                                                                                                                                                                                     & Validation 1448 Android apps from
F-Droid                                                                                                                                                                                                                                                                                                                                       \\
Brabra et al.\textbackslash{}cite\{brabra2019semantic\}        & \begin{tabular}[c]{@{}l@{}}\textbf{Validation 1}\\\textbf{}Average precision = 100\% \\Average recall = 95.1\% \\Average F-measure = 97,4\%\\\textbf{Validation 2}\\Average precision = 100\%\\Average recall = 91.2\% \\Average F-measure = 95.3\%\end{tabular}                                                                            & \begin{tabular}[c]{@{}l@{}}Validation 1 - OOi\\Validation 2 - Rackspace \\REST antipatterns\end{tabular}                                                                                                                                                                                                                                                                        \\
Palma et al.\textbackslash{}cite\{palma2018unidosa\}           & \begin{tabular}[c]{@{}l@{}}Average Precision = 89.78\% \\Average Recall = 96.67\% \\~Average F-measure = 91.3\%\end{tabular}                                                                                                                                                                                                                & \begin{tabular}[c]{@{}l@{}}Validation average for REST, SOAPand SCA \\antipatterns combined\end{tabular}                                                                                                                                                                                                                                                                        \\
Alshraiedeh et al.\textbackslash{}cite\{alshraiedeh2020uri\}   & \begin{tabular}[c]{@{}l@{}}\textbf{Ambiguous names} \\Average precision = 87.56\% \\Average recall = 81.19\%\\Average F-measure = 84.18\%\textbf{}\\\textbf{Amorphous URIs }\\Average precision = 88.17\%\\Average recall = 83.42\%\\Average F-measure = 85.68\%\end{tabular}                                                               & \begin{tabular}[c]{@{}l@{}}Validation results per antipattern \textbf{}\\\textbf{}\end{tabular}                                                                                                                                                                                                                                                                                
\end{tabular}
\end{table}
\end{document}